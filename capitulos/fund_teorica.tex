\chapter{Fundamentação Teórica}
\label{cap:fund_teorica}

\section{Avaliações no \textit{Google Maps}}
\label{cap:fund_teorica:sec:google_maps}

O \textit{Google Maps} \cite{wiki:googlemaps2023} é uma das ferramentas de mapeamento e navegação mais populares do mundo, desenvolvida e mantida pela Google. Lançado em 2005, o \textit{Google Maps} rapidamente se tornou uma ferramenta essencial para milhões de pessoas ao redor do mundo, oferecendo mapas detalhados, direções de navegação, informações sobre o tráfego em tempo real e uma ampla gama de recursos adicionais, como visualização de imagens de satélite, avaliações de estabelecimentos comerciais e muito mais.

Um dos recursos interessantes do \textit{Google Maps} é o programa \textit{"Local Guides"}~\cite{google2022localguides}. Este programa foi introduzido pela Google para incentivar os usuários a contribuir com informações adicionais sobre lugares e estabelecimentos em suas comunidades locais. Os \textit{"Local Guides"}~são usuários voluntários que compartilham avaliações, fotos, informações sobre horários de funcionamento, preços e outros detalhes úteis sobre restaurantes, lojas, atrações turísticas e outros pontos de interesse.

Os \textit{"Local Guides"}~são incentivados pela Google a contribuir com conteúdo de qualidade, e em troca, eles podem ganhar pontos, níveis e até mesmo recompensas, como armazenamento adicional no Google Drive, acesso antecipado a novos recursos do \textit{Google Maps} e até mesmo convites para eventos exclusivos. Essa gamificação do processo de contribuição ajuda a manter os usuários engajados e motivados a compartilhar informações úteis.

Além disso, os \textit{"Local Guides"}~desempenham um papel importante na melhoria contínua da precisão e da utilidade do \textit{Google Maps}. Ao fornecer informações atualizadas e detalhadas sobre os locais, eles ajudam outros usuários a tomar decisões informadas sobre aonde ir e o que fazer. Essa contribuição colaborativa cria uma comunidade global de usuários que trabalham juntos para tornar o \textit{Google Maps} uma ferramenta ainda mais poderosa e abrangente.

Em resumo, o \textit{Google Maps} é uma ferramenta essencial para navegação e descoberta de lugares, enquanto os \textit{"Local Guides"}~são membros voluntários da comunidade que contribuem com informações valiosas para melhorar a precisão e utilidade do serviço. Juntos, eles desempenham um papel crucial na criação de uma experiência de mapeamento e navegação mais rica e envolvente para todos os usuários.

A funcionalidade de avaliação de estabelecimentos no \textit{Google Maps} é uma ferramenta poderosa que oferece aos usuários uma maneira de compartilhar suas experiências e opiniões sobre diferentes locais, desde restaurantes e cafés até hotéis e pontos turísticos. Essa funcionalidade permite que os usuários forneçam opinião valiosa sobre a qualidade do serviço, a atmosfera do local, a qualidade dos produtos e uma infinidade de outros aspectos.

Uma das principais vantagens dessa funcionalidade é a capacidade de ajudar outros usuários a tomar decisões informadas ao escolherem um estabelecimento para visitar. As avaliações e comentários fornecidos por outros usuários podem servir como uma referência confiável, permitindo que as pessoas tenham uma noção melhor do que esperar de um determinado local antes de decidirem visitá-lo.

Além disso, o sistema de avaliação do \textit{Google Maps} geralmente é muito acessível e fácil de usar. Os usuários podem rapidamente atribuir uma classificação de estrelas e deixar um comentário detalhado sobre sua experiência com apenas alguns cliques, ajudando a manter uma base de dados robusta e atualizada sobre os estabelecimentos locais.

No entanto, é importante reconhecer que nem todas as avaliações podem ser completamente imparciais ou precisas. Algumas podem ser tendenciosas ou baseadas em experiências individuais que podem não refletir a experiência média dos clientes. Portanto, é sempre aconselhável considerar várias avaliações e fontes de informações ao tomar uma decisão.

Portanto, a funcionalidade de avaliação de estabelecimentos no \textit{Google Maps} oferece aos usuários uma maneira conveniente de compartilhar e acessar informações sobre locais, ajudando a tornar as experiências de viagem e exploração mais informadas e satisfatórias.

\section{Processamento de Linguagem Natural}

\subsection{Grandes Modelos de Linguagem}
\label{cap:fund_teorica:sec:modelos}

%\subsection[Large Language Models]{LLM}
%\label{cap:fund_teorica:sec:modelos:subsec:LLM}
% TODO LLM
% https://arxiv.org/pdf/2307.06435.pdf
% \cite{naveed2024comprehensive}

Neste projeto foram utilizados Grandes Modelos de linguagem(\textit{Large Language Models} - LLM) pré-treinados, como o \textit{GPT} (\textit{Generative Pre-trained Transformer}), \textit{OpenChat} e \textit{Vicuna}, além de modelos baseados na arquitetura \textit{BERT} (Bidirectional Encoder Representations from Transformers)\cite{hugoZanini2021mediu}. Esses modelos representam o estado-da-arte em \textit{PLN} e têm demonstrado um desempenho significativo em uma variedade de tarefas, incluindo análise de sentimentos.

\subsubsection[BERT]{BERT}
\label{cap:fund_teorica:sec:modelos:subsec:bert}

Um modelo baseado em \textit{BERT}(\textit{Bidirectional Encoder Representations from Transformers})~\cite{devlin2019bert} é um tipo de modelo de linguagem pré-treinado desenvolvido pelo Google. \textit{BERT} é um modelo de aprendizado profundo que utiliza a arquitetura de \textit{transformers} para capturar representações bidirecionais de palavras em um texto. Isso significa que ele é capaz de entender o contexto de uma palavra com base em suas palavras vizinhas, tanto anteriores quanto posteriores, em uma sentença.

Os modelos BERT são uma família de modelos de linguagem baseados em \textit{transformers} que foram pré-treinados em grandes corpora de texto. Eles são capazes de capturar o contexto bidirecional das palavras em uma frase, o que os torna especialmente eficazes para tarefas de análise de sentimentos, onde o contexto é crucial para determinar o sentimento expresso.

O treinamento de \textit{BERT} é realizado com abundância de dados de texto, onde o modelo aprende a prever palavras em uma frase ou sentença com base no contexto global da sentença. Como resultado, \textit{BERT} é capaz de capturar nuances e complexidades da linguagem natural de uma maneira mais eficaz do que modelos mais simples.

Após pré-treinado em um grande corpus de texto, um modelo \textit{BERT} pode ser ajustado para tarefas específicas, como análise de sentimentos, classificação de texto, resposta a perguntas, entre outras, por meio de um processo chamado de ajuste fino (\textit{fine-tuning}). Durante o ajuste fino, o modelo é treinado em um conjunto de dados rotulado específico para a tarefa em questão, adaptando suas representações aprendidas durante o pré-treinamento para a tarefa específica.

Os modelos baseados em \textit{BERT} tornaram-se amplamente populares e são frequentemente usados como base para uma variedade de tarefas de processamento de linguagem natural devido à sua capacidade de capturar contextos complexos e produzir resultados de alta qualidade, \textit{BERTs} treinados em português e com bom desempenho podemos citar o \textit{RoBERTa}~\cite{liu2019roberta} e BERTimbau~\cite{souza2020bertimbau}.

\subsubsection{Vicuna}
\label{cap:fund_teorica:sec:modelos:subsec:vicuna}

O \textit{Vicuna}~\cite{vicuna2023} é um modelo de assistente de chat desenvolvido pela \textit{LMSYS}~(\textit{Large Model Systems Organization}), ajustado a partir do modelo \textit{LLaMA} usando ajuste fino de instrução supervisionada. É um modelo de linguagem autorregressivo baseado na arquitetura \textit{transformers}, projetado para tarefas de geração de texto. Os dados de treinamento para o \textit{Vicuna} v1.5 consistem aproximadamente em 125.000 conversas coletadas do \textit{ShareGPT.com}, enquanto o \textit{Vicuna} v1.1 foi treinado com cerca de 70.000 conversas da mesma fonte.

\textit{Vicuna} é avaliado usando \textit{benchmarks} padrão, preferência humana e LLM-como-juiz, fornecendo uma avaliação abrangente de seu desempenho. É notável por alcançar mais de 90\% da qualidade do \textit{ChatGPT} em testes de preferência do usuário e superar significativamente o Alpaca, tornando-se um forte concorrente na família de modelos \textit{LLaMA} ajustados por instrução até maio de 2023.

O modelo está disponível no \textit{Hugging Face}, onde tem sido utilizado em vários espaços e projetos, indicando sua ampla adoção e aplicação na comunidade de desenvolvedores. No entanto, é importante notar que o \textit{Vicuna} está sujeito a uma licença não comercial, restringindo seu uso em aplicações comerciais.

Para aqueles interessados em começar com o \textit{Vicuna}, o cartão de modelo do \textit{Hugging Face} fornece informações detalhadas sobre detalhes do modelo, fontes, usos e como começar a trabalhar com o modelo. Além disso, há uma nota sobre uma versão mais recente dos pesos disponíveis, sugerindo que os usuários verifiquem atualizações para garantir que estejam usando a versão mais atual do modelo.

A versão utilizada neste projeto é o \textit{vicuna-1.5-13B} disponível para consulta no \textit{Hugging Face}~\cite{vicuna1513b}.

\subsubsection{GPT 3.5}
\label{cap:fund_teorica:sec:modelos:subsec:gpt}

O \texit{GPT}~\cite{enwiki:1226113577} é um modelo de código fechado e baseado em transformadores que aprende representações de linguagem generalizadas a partir de excesso de texto não rotulado. Ele é capaz de gerar texto coerente e relevante, e pode ser adaptado para tarefas específicas, como análise de sentimentos, através do treinamento supervisionado em conjuntos de dados rotulados.

O \textit{GPT}-3.5~\cite{openai:gpt35turbo}, introduzido pela OpenAI em março de 2022, é uma subclasse dos modelos \textit{GPT}-3 que representa um avanço significativo sobre seus predecessores. Ele é projetado para entender e gerar linguagem natural ou código, tornando-o adequado para uma ampla gama de aplicações, incluindo conversação e tarefas gerais. O \textit{GPT}-3.5 é notável por sua velocidade e flexibilidade, sendo mais rápido que o \textit{GPT}-3 e mais adaptável que o \textit{GPT} Base. É considerado o modelo "suficientemente bom"\ para a maioria das necessidades, oferecendo um equilíbrio entre desempenho e custo-efetividade. A variante \textit{GPT}-3.5 Turbo, em particular, é destacada como o melhor modelo da série \textit{GPT}-3.5, usado pela versão gratuita do \textit{ChatGPT} e elogiado por sua relação custo-eficácia e flexibilidade.

Os modelos GPT-3.5, incluindo a variante Turbo, têm um limite máximo de \textit{token} de 4.096 para a versão padrão e 16.384 para a versão Turbo-16k. Eles são treinados em dados até setembro de 2021, garantindo que tenham uma ampla base de conhecimento para se basear. A precificação~\cite{openai:gptpricing} para usar esses modelos é competitiva, com a variante Turbo custando \$0.0015 por 1.000 \textit{tokens} para entrada e \$0.002 por 1.000 \textit{tokens} para saída, enquanto a variante Turbo-16k custa \$0.0005 por 1.000 \textit{tokens} para entrada e \$0.0015 por 1.000 \textit{tokens} para saída.

\subsubsection{OpenChat}
\label{cap:fund_teorica:sec:modelos:subsec:openchat}

O OpenChat \cite{wang2024openchat} é um modelo de conversação que usa como modelo base o \textit{LLaMa} 2, usando ajuste fino com aprendizado supervisionado de aprendizagem por reforço condicionado. Ele é capaz de gerar respostas contextuais e relevantes em conversas humanas, o que pode servir para entender o contexto em avaliações de hotéis e extrair sentimentos.

É apresentado uma nova forma de ajuste fino de modelos, nomeado como \textit{OpenChat Framework}, que de forma sucinta consiste em realizar o ajuste fino do modelo utilizando um conjunto de dados que não é ótimo, ou seja, no conjunto de dados utilizado podemos ter dados com qualidade diferentes, de modo a aumentar a quantidade de dados que serão utilizadas no processo, porém de modo a realizar uma classificação para que o algoritmo de ajuste fino leve agora em consideração também a qualidade do dado utilizado.

O desempenho do OpenChat 13b se comprado a outros modelos com mesmo tamanho é bastante competitivo, tendo pontuação em \textit{AlapacaEval} e \textit{MT-bench} superiores aos valores de vicuna-v1.5-13b e o modelo base \textit{llama-2-13b}.

A versão utilizada neste projeto é o OpenChat-3.5-7B disponível para consulta no \textit{Hugging Face}~\cite{openChat357b}.

\subsection{Análise de Sentimentos}
\label{cap:fund_teorica:sec:analise_sentimento}

O Processamento de Linguagem Natural (PLN) é um campo de estudo que se concentra na interação entre computadores e linguagem humana. O objetivo principal do PLN é capacitar os computadores a entender, interpretar e gerar texto de forma semelhante aos seres humanos. Algumas das tarefas típicas do PLN incluem análise sintática, análise semântica, extração de informações e geração de linguagem natural~\cite{anchieta2021pln}.

A análise de sentimento é uma aplicação específica do PLN que se concentra na identificação e classificação das emoções expressas em textos~\cite{Liu2012}. Essa técnica é amplamente utilizada em diversas áreas, incluindo análise de mídia social, monitoramento de opinião pública, análise de opinião do cliente e tomada de decisões empresariais. A análise de sentimento é uma área de pesquisa em constante evolução, impulsionada pelo avanço das tecnologias de inteligência artificial e pela crescente disponibilidade de dados textuais. A compreensão dos conceitos e técnicas fundamentais nessas áreas é essencial para o desenvolvimento de sistemas eficazes de análise de sentimento, com aplicações em uma ampla gama de domínios, desde o marketing digital até a assistência virtual ao cliente.

O modelo de gráfico de nuvens de palavras é uma técnica de visualização frequentemente utilizada na análise de sentimentos para representar as palavras mais frequentes em um conjunto de dados de texto, com o tamanho das palavras proporcional à sua frequência de ocorrência. Neste contexto, as palavras são tipicamente coloridas de acordo com seu sentimento associado, o que facilita a identificação visual das palavras mais relevantes e das tendências sentimentais no texto.

Essa abordagem é valiosa na análise de sentimentos, pois permite uma rápida identificação de palavras-chave associadas a diferentes emoções, como positivas, negativas ou neutras. Ao visualizar um gráfico de nuvens de palavras, os analistas podem extrair percepções sobre as percepções dos usuários e as principais tendências de sentimentos presentes nos comentários ou avaliações de um determinado produto, serviço ou tópico.

Além das nuvens de palavras, outras técnicas e modelos são utilizados na análise de sentimento, incluindo:

\begin{itemize}
    \item \textbf{Modelos Baseados em Regras}: Utilizam léxicos de sentimentos, como \textit{SentiWordNet} \cite{Baccianella2010} e \textit{VADER} \cite{Hutto2014}, para atribuir valores de polaridade às palavras e calcular o sentimento geral do texto.
    \item \textbf{Modelos de \textit{Machine Learning}}: Utilizam algoritmos supervisionados, como \textit{Naive Bayes}, \textit{SVM} e \textit{Random Forest}, treinados em grandes corpora anotados para classificar o sentimento de novos textos \cite{Pang2002, Liu2012}.
    \item \textbf{Modelos de \textit{Deep Learning}}: Redes neurais profundas, como \textit{LSTM} e \textit{transformers} (ex.: BERT \cite{Devlin2019}), são capazes de capturar dependências contextuais complexas e proporcionar resultados de alta precisão na análise de sentimentos \cite{Zhang2018}.
\end{itemize}

Esses métodos variam em complexidade e aplicabilidade, dependendo da natureza dos dados e dos requisitos específicos do problema de análise de sentimentos.

A análise de sentimentos enfrenta diversos desafios, incluindo a detecção de sarcasmo e ironia, a ambiguidade lexical e a necessidade de contextualização. Além disso, a evolução constante da linguagem, especialmente em plataformas de mídia social, requer modelos adaptáveis e atualizados regularmente para manter a precisão e relevância.

% \subsubsection{Aplicações Práticas da Análise de Sentimentos}

A análise de sentimentos tem uma ampla gama de aplicações práticas como, por exemplo, análise de sentimento de \textit{tweets} para serem utilizados para predizer o resultado das eleições ou como forma de antecipar movimento do mercado financeiro, entre outras diversas aplicações \cite{Liu2012}.

A análise de sentimento é uma aplicação específica do \textit{PLN} que se concentra na identificação e classificação das emoções expressas em textos. Essa técnica é amplamente utilizada em diversas áreas, incluindo análise de mídia social, monitoramento de opinião pública, análise de opinião do cliente e tomada de decisões empresariais. A análise de sentimento é uma área de pesquisa em constante evolução, impulsionadas pelo avanço das tecnologias de inteligência artificial e pela crescente disponibilidade de dados textuais. A compreensão dos conceitos e técnicas fundamentais nessas áreas é essencial para o desenvolvimento de sistemas eficazes de análise de sentimento, com aplicações em uma ampla gama de domínios, desde o marketing digital até a assistência virtual ao cliente.
